# 并发编程 (三)

# 1 Fork/Join分解合并框架

## 1.1 什么是fork/join

​	Fork/Join框架是JDK1.7提供的一个用于并行执行任务的框架，开发者可以在不去了解如Thread、Runnable等相关知识的情况下，只要遵循fork/join开发模式，就完成写出很好的多线程并发任务。

​	同时其按照**分而治之**的思想，可以把一个大任务分割成若干个小任务，最终汇总每个小任务结果后得到大任务结果的框架。

​	对于Fork/Join框架的理解可以认为其由两部分组成，Fork就是把一个大任务切分为若干个子任务并行执行。Join就是合并这些子任务的执行结果，最后得到这个大任务的结果。

![image-20200730151437185](assets/image-20200730151437185.png)

## 1.2 工作窃取算法

​	即当前线程的 Task 已经全被执行完毕，则自动取到其他线程的 Task 池中取出 Task 继续执行。ForkJoinPool 中维护着多个线程（一般为 CPU 核数）在不断地执行 Task，每个线程除了执行自己任务列表内的 Task 之外，还会根据自己工作线程的闲置情况去获取其他繁忙的工作线程的 Task，如此一来就能能够减少线程阻塞或是闲置的时间，提高 CPU 利用率。

![image-20200730153133010](assets/image-20200730153133010.png)

## 1.3 Fork/Join的使用

### 1.3.1 基本概念

​	要使用Fork/Join的话，首先需要有一个Pool。通过它可以来执行任务。 而每一个任务叫做ForkJoinTask，其内部提供了fork和join的操作机制。通常情况下开发者不需要直接继承ForkJoinTask，而是继承它的子类。分别为：

- **RecursiveAction**：返回没有结果的任务。

- **RecursiveTask<T>**：返回有结果的任务。

![image-20200730155948459](assets/image-20200730155948459.png)

1）新建ForkJoinPool；

2）新建ForkJoinTask(RecursiveAction || RecursiveTask);

3）在任务中的compute方法，会根据自定义条件进行任务拆分，如果条件满足则执行任务，如果条件不满足则继续拆分任务。当所有任务都执行完，进行最终结果的汇总。

4）最终通过get或join获取数据结果。

### 1.3.2 同步有结果值返回

需求：统计整型数组中所有元素的和。

```java
//生成随机数组
public class GenArray {

    //数组长度
    public static final int ARRAY_LENGTH=400000;

    public static int[] genArray(){

        Random random = new Random();
        int[] result = new int[ARRAY_LENGTH];
        for (int i = 0; i < ARRAY_LENGTH; i++) {
            //随机数填充数组
            result[i]= random.nextInt(ARRAY_LENGTH*3);
        }
        return result;
    }
}
```

```java
//普通循环累加
public class SumNormal {

    public static void main(String[] args) {

        int count = 0;
        int[] src = GenArray.genArray();

        long start = System.currentTimeMillis();

        for (int i = 0; i < src.length; i++) {
            count+=src[i];
        }

        System.out.println("spend time: "+(System.currentTimeMillis()-start));
    }
}
```

```java
//forkJoin累加
public class SumForkJoin{

    //自定义任务
    private static class SumTask extends RecursiveTask<Integer> {

        private final static int THRESHOLD=GenArray.ARRAY_LENGTH/10;
        private int[] src;
        private int fromIndex;
        private int endIndex;

        public SumTask(int[] src, int fromIndex, int endIndex) {
            this.src = src;
            this.fromIndex = fromIndex;
            this.endIndex = endIndex;
        }

        @Override
        protected Integer compute() {

            //判断是否符合任务大小
            if (endIndex-fromIndex<THRESHOLD){
                //符合条件
                int count = 0;
                for (int i = fromIndex; i <= endIndex; i++) {
                    count+=src[i];
                }
                return count;
            }else {
                //继续拆分任务
                //基于二分查找对任务进行拆分
                int mid = (fromIndex+endIndex)/2;
                SumTask left = new SumTask(src,fromIndex,mid);
                SumTask right = new SumTask(src,mid+1,endIndex);
                invokeAll(left,right);
                return left.join()+right.join();
            }
        }
    }

    public static void main(String[] args) {

        ForkJoinPool pool = new ForkJoinPool();

        int[] src = GenArray.genArray();
        SumTask sumTask = new SumTask(src,0,src.length-1);

        long start = System.currentTimeMillis();
        pool.invoke(sumTask);
        System.out.println("spend time: "+(System.currentTimeMillis()-start));
    }
}
```

​	根据执行结果可以看到，如果数据量较小的情况下，使用普通循环的效率更高，因为其内部是以总线的形式进行相加。而forkjoin的话，要利用当前可用的CPU核数结合线程的上下文切换，所以存在一定的性能消耗。

​	但是如果数据量较大的话，可以看到使用forkjoin的效率会明显高于普通for循环。

### 1.3.3 异步无结果值返回

需求：遍历目录（包含子目录）寻找txt类型文件。

```java
public class FindFile extends RecursiveAction {

    private File path;

    public FindFile(File path) {
        this.path = path;
    }

    @Override
    protected void compute() {
        List<FindFile> takes = new ArrayList<>();

        //获取指定路径下的所有文件
        File[] files = path.listFiles();

        if (files != null){
            for (File file : files) {
                //是否为文件夹
                if (file.isDirectory()){
                    //递归调用
                    takes.add(new FindFile(file));
                }else {
                    //不是文件夹。执行检查
                    if (file.getAbsolutePath().endsWith("txt")){
                        System.out.println(file.getAbsolutePath());
                    }
                }
            }

            //调度所有子任务执行
            if (!takes.isEmpty()){
                for (FindFile task : invokeAll(takes)){
                    //阻塞当前线程并等待获取结果
                    task.join();
                }
            }
        }
    }

    public static void main(String[] args) {

        ForkJoinPool pool = new ForkJoinPool();

        FindFile task = new FindFile(new File("F://"));

        pool.submit(task);

        //主线程join，等待子任务执行完毕。
        task.join();

        System.out.println("task end");
    }
}
```

# 2 并发工具类

​	在JDK并发包下提供了几个很有用的并发工具类。CountDownLatch、CyclicBarrier、Semaphore、Exchanger。通过他们可以在不同场景下完成一些特定的功能。

## 2.1 CountDownLatch闭锁

### 2.1.1 简介

​	CountDownLatch一般会把它称之为**闭锁**，其**允许一个或多个线程等待其他线程完成操作**。

![image-20200730194204167](assets/image-20200730194204167.png)

​	CountDownLatch内部是通过计数器实现，当执行到某个节点后，就会开始等待其他任务执行。每完成一个任务，计数器就会减一，当计数器等于0时，代表任务已全部完成，则恢复之前的等待线程继续向下运行。

### 2.1.2 使用场景

​	根据其工作的特性，使用的场景也是比较多的。假设现在要解析一个Excel文件，其内部会存在多个sheet，则设定每个线程解析一个sheet，等到解析完所有sheet后。再进行后续操作。这就是一个很常见的场景。

### 2.1.3 代码实现

```java
public class CountDownLatchDemo {

    static CountDownLatch countDownLatch = new CountDownLatch(5);

    //任务线程
    private static class TaskThread implements Runnable{

        @Override
        public void run() {
            countDownLatch.countDown();
            System.out.println("task thread is running");
        }
    }

    //等待线程
    private static class WaitThread implements Runnable{

        @Override
        public void run() {
            try {
                countDownLatch.await();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            System.out.println("wait thread is running");
        }
    }

    public static void main(String[] args) throws InterruptedException {

        //等待线程执行
        for (int i = 0; i < 2; i++) {
            new Thread(new WaitThread()).start();
        }

        for (int i = 0; i < 5; i++) {
            new Thread(new TaskThread()).start();
        }

        TimeUnit.SECONDS.sleep(3);
    }
}
```

## 2.2 CycliBarrier同步屏障

### 2.2.1 简介

​	CycliBarrier翻译过来叫做**可循环的屏障**。其可以实现当一组线程执行时，当到达某个屏障（同步点）被阻塞，直到最后一个线程到达屏障后，才会让这一组线程继续向下执行。 其内部也是基于计数器思想实现。

![image-20200730204742730](assets/image-20200730204742730.png)

​	对于CycliBarrier来说，其在基本流程的基础上，也进行了一个扩展。查看源码可知，其构造函数不仅可以传入需要等待的线程数，同时还可以传入一个Runnable。对于这个runnable可以作为一个扩展任务来使用。

![image-20200730204940461](assets/image-20200730204940461.png)

### 2.2.2 代码实现

#### 2.2.2.1 基础实现

```java
public class CyclicBarrierDemo {

    static CyclicBarrier barrier = new CyclicBarrier(3);

    public static void main(String[] args) throws InterruptedException {
        new Thread(()->{

            try {
                System.out.println(Thread.currentThread().getName()+": do somethings");
                barrier.await();
            } catch (InterruptedException e) {
                e.printStackTrace();
            } catch (BrokenBarrierException e) {
                e.printStackTrace();
            }
            System.out.println(Thread.currentThread().getName()+":continue somethings");
        }).start();

        new Thread(()->{

            try {
                System.out.println(Thread.currentThread().getName()+": do somethings");
                barrier.await();
            } catch (InterruptedException e) {
                e.printStackTrace();
            } catch (BrokenBarrierException e) {
                e.printStackTrace();
            }
            System.out.println(Thread.currentThread().getName()+":continue somethings");
        }).start();

        //主线程
        try {
            System.out.println(Thread.currentThread().getName()+": do somethings");
            barrier.await();
        } catch (BrokenBarrierException e) {
            e.printStackTrace();
        }
        System.out.println(Thread.currentThread().getName()+":continue somethings");
    }
}
```

运行结果

```
Thread-0: do somethings
main: do somethings
Thread-1: do somethings
main:continue somethings
Thread-1:continue somethings
Thread-0:continue somethings
```

​	根据运行结果可知，子线程与主线程间首先会进行相互等待，只有等到其他线程都执行完毕后，才能继续向下执行。因为主线程和子线程是由CPU来进行调度，所以顺序不可控。

​	此时如果将线程数由3改为4则会永久等待，因为没有第四个线程执行await()方法，即没有第四个线程到达屏障，所以之前到达屏障的三个线程都不会继续向下执行。

#### 2.2.2.2 扩展实现

​	CyclicBarrier还提供了一个更高级的构造函数，不仅可以设置等待线程数量，同时还能够设置一个优先执行的Runnable，方便处理更为复杂的业务场景。

![image-20200730220902843](assets/image-20200730220902843.png)

![image-20200730223241276](assets/image-20200730223241276.png)

```java
public class CyclicBarrierDemo2 {

    static CyclicBarrier barrier = new CyclicBarrier(3,new ExtendTask());

    public static void main(String[] args) throws InterruptedException {
        new Thread(()->{

            try {
                System.out.println(Thread.currentThread().getName()+": do somethings");
                barrier.await();
            } catch (InterruptedException e) {
                e.printStackTrace();
            } catch (BrokenBarrierException e) {
                e.printStackTrace();
            }
            System.out.println(Thread.currentThread().getName()+":continue somethings");
        }).start();

        new Thread(()->{

            try {
                System.out.println(Thread.currentThread().getName()+": do somethings");
                barrier.await();
            } catch (InterruptedException e) {
                e.printStackTrace();
            } catch (BrokenBarrierException e) {
                e.printStackTrace();
            }
            System.out.println(Thread.currentThread().getName()+":continue somethings");
        }).start();

        //主线程
        try {
            System.out.println(Thread.currentThread().getName()+": do somethings");
            barrier.await();
        } catch (BrokenBarrierException e) {
            e.printStackTrace();
        }
        System.out.println(Thread.currentThread().getName()+":continue somethings");
    }

    static class ExtendTask implements Runnable{

        @Override
        public void run() {
            System.out.println("extend task running");
        }
    }
}
```

### 2.2.3 与CountDownLatch的区别

1）CountDownLatch.await 一般阻塞工作线程，所有的进行预备工作的线程执行countDown，而 CyclicBarrier 通过工作线程调用 await 从而自行阻塞，直到所有工作线程达到指定屏障，再大家一起往下走。

2）在控制多个线程同时运行上，CountDownLatch 可以不限线程数量，而CyclicBarrier 是固定线程数。

## 2.3 Semaphore信号量

### 2.3.1 简介

​	其可以用于做流量控制，通过控制同时访问资源的线程数量，从而保证资源能够被更加合理的使用，如连接资源。假设现在要获取几万个文件资源，那么现在可以开启若干线程进行并发读取。但是读取后还要把这些数据写入到数据库。而数据库连接现在只有100个，此时就需要人为干预，控制只有100个线程同时获取数据库连接资源保存数据。

![image-20200730223617565](assets/image-20200730223617565.png)

### 2.3.2 代码实现

```java
public class SemaphoreDemo {

    private static final int THREAD_COUNT=30;

    private static ExecutorService executorService = Executors.newFixedThreadPool(THREAD_COUNT);

    static Semaphore semaphore = new Semaphore(10);

    public static void main(String[] args) {
        for (int i = 0; i < THREAD_COUNT; i++) {
            executorService.execute(()->{

                try {
                    //获取资源
                    semaphore.acquire();
                    System.out.println("do somethings");
                    //释放资源
                    semaphore.release();
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }

            });
        }

        executorService.shutdown();
    }
}
```

​	根据上述实现，虽然有三十个线程执行，但是每次同时只能有十个线程能同时获取到资源。 如果将释放资源API注释，则只会有十条打印，因为资源已被耗尽，其他线程无法获取到资源。

## 2.4 Exchanger交换器

### 2.4.1 简介

​	Exchanger是一个线程协作工具类，**可以进行线程间的数据交换**，但是只局限于两个线程间协作。它提供了一个同步点，在这个同步点，两个线程可以交换彼此的数据。

![image-20200730225242985](assets/image-20200730225242985.png)

### 2.4.2 代码实现

```java
public class ExchangerDemo {

    private static final Exchanger<Set<String>> exchange = new Exchanger<Set<String>>();

    public static void main(String[] args) {

        new Thread(new Runnable() {
            @Override
            public void run() {
                Set<String> setA = new HashSet<String>();//存放数据的容器
                try {
                    setA.add("a1");
                    setA = exchange.exchange(setA);//交换set
                    /*处理交换后的数据*/
                    System.out.println(Thread.currentThread().getName()+" : "+setA.toString());
                } catch (InterruptedException e) {
                }
            }
        },"setA").start();

        new Thread(new Runnable() {
            @Override
            public void run() {
                Set<String> setB = new HashSet<String>();//存放数据的容器
                try {
                    /*添加数据
                     * set.add(.....)
                     * set.add(.....)
                     * */
                    setB.add("a2");
                    setB = exchange.exchange(setB);//交换set
                    /*处理交换后的数据*/
                    System.out.println(Thread.currentThread().getName()+" : "+setB.toString());
                } catch (InterruptedException e) {
                }
            }
        },"setB").start();

    }
}
```

运行结果

```
setB : [a1]
setA : [a2]
```

# 3 Map解析

## 3.1 HashMap分析

### 3.1.1 JDK7的HashMap

​	HashMap在日常开发中是很常见的，在JDK7中其底层是由**数组+链表**构成，数组被分成一个个桶(bucket)，通过哈希值决定了键值对在这个数组中的位置。哈希值相同的键值对，会以链表形式进行存储。每一个键值对会以一个Entry实例进行封装，内部存在四个属性：key，value，hash值，和用于单向链表的next。

![image-20200731002740068](assets/image-20200731002740068.png)

​	当对HashMap初始化时，其构造函数中需要传入两个参数：**initialCapacity**、**loadFactor**

![image-20200731004046760](assets/image-20200731004046760.png)

​	hashMap中还有一个变量：**threshold**（扩容阈值。计算公式：**capacity * load factor**）

![image-20200731004212717](assets/image-20200731004212717.png)

​	**添加数据过程（put）**

1. 在第一个元素插入HashMap时做一次数组的初始化，先确定初始的数组大小，并计算数组扩容的阈值。
2. 使用key进行Hash值计算，**然后通过 `(n - 1) & hash` 判断当前元素存放的位置（这里的 n 指的是数组的长度）**，用于确定当前键值对要放入哪个Bucket中。
3. 找到Bucket后，**如果当前位置存在元素的话，就判断该元素与要存入的元素的 hash 值以及 key 是否相同**；如果没有重复，则将此Entry放入链表的**头部**；如果出现重复，则将此Entry放入链表的尾部，同时建立与前一个节点的连接。
4. 在插入新值时，如果当前Buckets数组大小达到了阈值，则触发扩容。扩容后，为原大小的两倍。**扩容时会产生一个新的数组替换原来的数组，并将原来数组中的值迁移到新数组中**。

​	**查询数据过程（get）**

1. 根据key计算hash值。
2. 根据hash值确定Bucket。
3. 遍历Bucket下的链表，直到找到对应的key。

### 3.1.2 JDK8的HashMap

​	JDK8中对于HashMap的存储结构进行了优化，由**数组+链表+红黑树**组成。这么做的原因是因为：之前查找元素需要遍历链表，时间复杂度取决于链表的长度。

​	为了优化这部分的开销，在JDK中，如果链表中元素**大于等于8个**，则将链表转换为红黑树（**前提是桶的大小达到64，否则会先对桶进行扩容**）；当红黑树中元素**小于等于6个**，则将红黑树转为链表。从而降低查询与添加的时间复杂度。

![image-20200731010255562](assets/image-20200731010255562.png)

### 3.1.3 JDK7的HashMap扩容流程

#### 3.1.3.1 API调用过程

1）当调用HashMap的put方法时，其内部会调用**addEntry**方法添加元素。

![image-20200731021106237](assets/image-20200731021106237.png)

2）在**addEntry**中，如果条件满足则调用**resize**方法进行扩容。扩展为原大小的两倍。

![image-20200731021243689](assets/image-20200731021243689.png)

3）在**resize**方法中，会调用**transfer**方法根据新的容量去创建新的Entry数组，命名为newTable。

![image-20200731021526950](assets/image-20200731021526950.png)

4）在**transfer**方法中会轮询原table中的每一个Entry重新计算其在新Table上的位置，并以链表形式连接

![image-20200731022228069](assets/image-20200731022228069.png)

5）当全部轮询完毕，则在resize方法中将原table替换为新table。

![image-20200731022424103](assets/image-20200731022424103.png)

#### 3.1.3.2 图例分析

1）假设现在有一个hashMap，buckets数组大小为2，内部存在三个元素。假设现在通过key%buckets长度，则3、5、7%2 都为1，则这三个元素都进入1号中，形成一个链表。

![image-20200731023154668](assets/image-20200731023154668.png)

2）当发生扩容时，根据源码会对原数组进行二倍扩容，则现在buckets数组长度为4。

![image-20200731023744623](assets/image-20200731023744623.png)

3）当在transfer方法中对原数组中Entry进行遍历时，首先遍历到key为3的元素，此时需要通过3%4=3。所以该Entry会放入三号桶中。

![image-20200731024405464](assets/image-20200731024405464.png)

4）接着遍历到key为7的元素，此时取模结果仍为3，则该Entry也会放入三号桶中。但是在HashMap中采用的是**头插法**，后进来的元素会放在队列的头部。

![image-20200731024825537](assets/image-20200731024825537.png)

![image-20200731024932590](assets/image-20200731024932590.png)

5）接着遍历到key为5的元素，此时取模结果为1，则该Entry放入一号桶中。

![image-20200731025008508](assets/image-20200731025008508.png)

### 3.1.4 hashMap死循环

​	在JDK8之前，生产环境下的系统经常会出现CPU100%占用，当查看堆栈信息，经常发现程序都卡在了hashMap.get()上，当将系统重启就好了。但是过了一段时间就又会这样，而且在测试环境时又没有问题。后来发现是因为在多线程操作hashMap，当进行rehash时，会造成hashMap出现死循环，原因就在于其内部会形成一个循环链表。 该问题在JDK8之后得以解决，但是仍然不推荐在多线程环境下直接使用HashMap，因为有可能会造成数据丢失，建议使用ConcurrentHashMap。

#### 3.1.4.1 死循环出现原因分析

```java
void transfer(Entry[] newTable, boolean rehash) {
    int newCapacity = newTable.length;
    //从oldTable中获取元素，并放入newTable中。
    for (Entry<K,V> e : table) {
        while(null != e) {
            Entry<K,V> next = e.next;
            if (rehash) {
                e.hash = null == e.key ? 0 : hash(e.key);
            }
            int i = indexFor(e.hash, newCapacity);
            e.next = newTable[i];
            newTable[i] = e;
            e = next;
        }
    }
}
```

#### 3.1.4.2 单线程下的Rehash

​	假设了我们的hash算法就是简单的用key mod 一下表的大小（也就是数组的长度）。其中的Hash表的size=2, 所以key = 3, 7, 5，在mod 2以后都冲突在table[1]里。效果如下：

![image-20201010230746517](assets/image-20201010230746517.png)

​	此时执行数组扩容，按照扩容规则，buckets数组扩容为原大小的两倍，变为长度为4，接着进行rehash重新计算原数组中元素在新数组中的位置。

![image-20201010230802944](assets/image-20201010230802944.png)

第一次操作完后，key:3 放入到buckets[3]的位置，此时e指向原数组中的7，e.next也为7，结构如下所示：

![image-20201010230818046](assets/image-20201010230818046.png)

​	接着进入到第二次循环，此时e为7，当执行`Entry<K,V> next = e.next`时，next指向5。接着执行后续逻辑，效果如下所示：

![image-20201010230834296](assets/image-20201010230834296.png)

​	第二次操作完后，key:7放入到buckets[3]的位置，并且处于key:3的前面。继续进行遍历，此时e为5，e.next为null。

![image-20201010230852927](assets/image-20201010230852927.png)

根据当前流程可以发现，当在JDK7中的hashmap采用的是头插法，会将扩容之前的元素顺序进行反转。

#### 3.1.4.3 并发下的Rehash

假设现在有两个线程，红色为线程一，蓝色为线程二。

扩容前hash结构

![image-20201010230930031](assets/image-20201010230930031.png)

此时两个线程同时执行，因为hashmap不能保证线程安全，所以两个操作的是同一个hashmap空间。当进入到transfer()，在执行完`Entry<K,V> next = e.next`时，两个线程状态如下所示：

![image-20201010230946325](assets/image-20201010230946325.png)

假设线程一在执行到`Entry<K,V> next = e.next;`时被挂起了，那么此时线程一记录的e为3，e.next为7。结构如下

接着线程二执行，将整个rehash过程执行完毕。执行完毕效果如下：

![image-20201010231001524](assets/image-20201010231001524.png)

接着线程一开始执行，但是线程一之前的记录为e为key3，e.next为key7。因此继续执行的话，会指向线程二Rehash之后的链表。形成结构如下：

![image-20201010231017073](assets/image-20201010231017073.png)

此时可以发现问题，按理说，e应该是在next的前面，但是现在顺序发生问题了。

线程一操作的就是线程二Rehash之后的hashMap

![image-20201010231035367](assets/image-20201010231035367.png)

接着线程一继续执行后续代码

![image-20201010231049347](assets/image-20201010231049347.png)

当一次循环后，效果如下所示：

![image-20201010231103827](assets/image-20201010231103827.png)

接着进行第二次循环。此时e指向7，当执行`Entry<K,V> next = e.next`时，此时next指向3。效果如下所示：

![image-20201010231118110](assets/image-20201010231118110.png)

接着继续循环执行，效果如下所示：

![image-20201010231137405](assets/image-20201010231137405.png)

此时可以发现，当这次循环完之后，3中的next指向7，7中的next指向3.此时死循环已经出现。

### 3.1.5 JDK8的HashMap源码分析

##### 3.1.5.1 put流程

```java
/**
     * Implements Map.put and related methods
     *
     * @param hash hash for key
     * @param key the key
     * @param value the value to put
     * @param onlyIfAbsent if true, don't change existing value
     * @param evict if false, the table is in creation mode.
     * @return previous value, or null if none
     */
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
               boolean evict) {
    Node<K,V>[] tab; Node<K,V> p; int n, i;
    //初始化时，map中还没有key-value
    if ((tab = table) == null || (n = tab.length) == 0)
        //利用resize生成对应的tab[]数组
        n = (tab = resize()).length;
    if ((p = tab[i = (n - 1) & hash]) == null)
        //当前桶无元素
        tab[i] = newNode(hash, key, value, null);
    else {//桶内有元素
        Node<K,V> e; K k;
        if (p.hash == hash &&
            ((k = p.key) == key || (key != null && key.equals(k))))
            //桶内第一个元素的key等于待放入的key
            e = p;
        else if (p instanceof TreeNode)
            //如果此时桶内已经树化
            e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
        else {//桶内还是一个链表，则插入链尾（尾插）
            for (int binCount = 0; ; ++binCount) {
                if ((e = p.next) == null) {
                    p.next = newNode(hash, key, value, null);
                    if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                        //变成红黑树
                        treeifyBin(tab, hash);
                    break;
                }
                if (e.hash == hash &&
                    ((k = e.key) == key || (key != null && key.equals(k))))
                    break;
                p = e;
            }
        }
        if (e != null) { // existing mapping for key
            V oldValue = e.value;
            if (!onlyIfAbsent || oldValue == null)
                e.value = value;
            afterNodeAccess(e);
            return oldValue;
        }
    }
    //检查是否应该扩容
    ++modCount;
    if (++size > threshold) 
        resize();
    afterNodeInsertion(evict);
    return null;
}
```

![image-20200824211812307](assets/image-20200824211812307.png)

### 3.1.6 jdk 7 与 jdk 8 中关于HashMap的对比

- 8时红黑树+链表+数组的形式，当桶内元素大于8时，便会树化
- 1.7 table在创建hashmap时分配空间，而1.8在put的时候分配，如果table为空，则为table分配空间。
- 在发生冲突，插入链中时，7是头插法，8是尾插法。

### 3.1.7 相关面试

```
Q：hashmap原理，内部数据结构？
A：底层使用哈希表（数组+链表）。当链表长度8，会将链表转为红黑树，用以优化查询效率。当链表长度小于6，会将红黑树转为链表
```

```
Q:描述一下hashmap的put过程？
A：
1）对key求hash值，（n-1）&hash用以计算桶的小标
2）如果没有碰撞，直接放入桶中。
3）如果碰撞了，插入到链表的末尾。
4）如果链表长度超过8,并且数组长度大于64，则链表转为红黑树。
5）如果节点已经存在就替换旧值。
6）如果桶满了（容量*负载因子），则需要扩容，默认两倍。
```

```
Q:HashMap如何解决键冲突
A:当出现冲突会将新节点加入链表的末尾， jdk7插入头部，jdk8插入尾部。
```

```
Q:扩容流程是什么样的？
A：容量扩容为原来的两倍，然后对每个节点重新计算哈希值/
```

## 3.2 ConcurrentHashMap解析

### 3.2.1 简介

​	ConcurrentHashMap是一个线程安全且高效的HashMap。在并发下，推荐使用其替换HashMap。对于它的使用也非常的简单，除了提供了线程安全的get和put之外，它还提供了一个非常有用的方法**putIfAbsent**，如果传入的键值对已经存在，则返回存在的value，不进行替换； 如果不存在，则添加键值对，返回null。

```java
public class MapDemo {

    public static void main(String[] args) {

        ConcurrentHashMap<String,String> map = new ConcurrentHashMap<>();

        System.out.println("put不存在的值------");
        System.out.println(map.put("AA","AA"));
        System.out.println(map.get("AA"));

        System.out.println("put已存在的key-------------");
        System.out.println(map.put("BB","BB"));
        System.out.println(map.get("BB"));

        System.out.println("putIfAbsent已存在的key-------------");
        System.out.println(map.putIfAbsent("AA","AA"));
        System.out.println(map.get("AA"));

        System.out.println("putIfAbsent不存在的key-------------");
        System.out.println(map.putIfAbsent("CC","CC"));
        System.out.println(map.get("CC"));
    }
}
```

### 3.2.2 JDK7的ConcurrentHashMap

#### 3.2.2.1 基础结构

![image-20200731103926288](assets/image-20200731103926288.png)

​	一个ConcurrentHashMap里包含一个Segment数组，结构与HashMap类似（数组+链表）。一个Segment中包含一个HashEntry数组，每个HashEntry就是链表的元素。

​	Segment是ConcurrentHashMap实现的很核心的存在，Segment翻译过来就是一段，一般把它称之为**分段锁**。它继承了ReentrantLock，在ConcurrentHashMap中相当于锁的角色，在多线程下，不同的线程操作不同的segment。只要锁住一个 segment，其他剩余的Segment依然可以操作。这样只要保证每个 Segment 是线程安全的，我们就实现了全局的线程安全。

​	HashEntry则用于存储键值对。

![image-20200731103625652](assets/image-20200731103625652.png)

![image-20200731103639254](assets/image-20200731103639254.png)

#### 3.2.2.2 构造方法和初始化

​	![image-20200731110517277](assets/image-20200731110517277.png)

![image-20200731110535624](assets/image-20200731110535624.png)

​	根据其构造函数可知，map的容量默认为16，负载因子为0.75。这两个都与原HashMap相同，但不同的在于，其多个参数**concurrencyLevel(并发级别)**，通过该参数可以用来确定Segment数组的长度并且不允许扩容，默认为16。

​	并发度设置过小会带来严重的锁竞争问题；如果过大，原本位于一个segment内的访问会扩散到不同的segment中，导致查询命中率降低，引起性能下降。

#### 3.2.2.3 API解析

##### 3.2.2.3.1 get()

![image-20200731111827151](assets/image-20200731111827151.png)

1）根据key计算出对应的segment

2）获取segment下的HashEntry数组

3）遍历获取每一个HashEntry进行比对。

注意：整个get过程没有加锁，而是通过volatile保证可以拿到最新值。

##### 3.2.2.3.2 put()

​	初始化segment，因为ConcurrentHashMap初始化时只会初始化segment[0]，对于其他的segment，在插入第一个值的时候再进行初始化。经过计算后，将对应的segment完成初始化。

![image-20200731114338096](assets/image-20200731114338096.png)

​	向下调用ensureSegment方法，其内部可以通过cas保证线程安全，让多线程下只有一个线程可以成功。

![image-20200731114609992](assets/image-20200731114609992.png)

​	在put方法中当初始化完Segment后，会调用一个put的重载方法进行键值对存放。首先会调用tryLock()尝试获取锁，node为null进入到后续流程进行键值对存放；如果没有获取到锁，则调用**scanAndLockForPut()**自旋等待获得锁。

![image-20200731115029471](assets/image-20200731115029471.png)

​	在**scanAndLockForPut()**方法中首先会根据链表进行遍历，如果遍历完毕仍然找不到与key相同的HashEntry，则提前创建一个HashEntry。**当tryLock一定次数后仍然无法获得锁，则主动通过lock申请锁。**

![image-20200731115757790](assets/image-20200731115757790.png)

​	在获得锁后，segment对链表进行遍历，如果某个 HashEntry 节点具有相同的 key，则更新该 HashEntry 的 value 值，否则新建一个节点将其插入链表头部。

​	如果节点总数超过阈值，则调用rehash()进行扩容。

![image-20200731120044567](assets/image-20200731120044567.png)

### 3.2.3 JDK8的ConcurrentHashMap

#### 3.2.3.1 与JDK7的区别

​	在JDK1.8中对于ConcurrentHashMap也进行了升级，主要优化点如下：

1）JDK7中使用CAS+Reentrant保证并发更新的安全，而在JDK8是通过CAS+synchronized保证。因为synchronized拥有了优化，在低粒度加锁下，synchronized并不比Reentrant差；在大量数据操作下，对于JVM的内存压力，基于API的ReentrantLock会开销更多的内存。

2）JDK7的底层使用**segment+数组+链表**组成。而在JDK8中抛弃了segment，转而使用**数组+链表+红黑树**的形式实现，从而让锁的粒度能够更细，进一步减少并发冲突的概率；同时也提高的数据查询效率。

3）在JDK7中的HashEntry在JDK8中变为Node，当转化为红黑树后，变为TreeNode。转换的规则与hashMap相同，当链表长度大于等于8则转换为红黑树，当红黑树的深度小于等于6则转换为链表。

![image-20200731143343799](assets/image-20200731143343799.png)

#### 3.2.3.2 核心属性

**Node类**：用于存储键值对。其与JDK7中的HashEntry属性基本相同。

![image-20200731151431163](assets/image-20200731151431163.png)

**TreeNode类**：树节点类，当链表长度大于等于8，则转换为TreeNode。与hashMap不同的地方在于，它并不是直接转换为红黑树，而是把这些节点放在TreeBin对象中，由TreeBin完成红黑树的包装。

![image-20200731151414233](assets/image-20200731151414233.png)

**TreeBin类**：负责TreeNode节点包装，它代替了TreeNode的根节点，也就是说在实际的数组中存放的是TreeBin对象，而不是TreeNode对象。

![image-20200731151649980](assets/image-20200731151649980.png)

**sizeCtl属性**：用于控制table的初始化和扩容。-1表示正在初始化，-N表示由N-1个线程正在进行扩容，0为默认值表示table还没被初始化，正数表示初始化大小或Map中的元素达到这个数量时，则需要扩容了。

![image-20200731160623150](assets/image-20200731160623150.png)

#### 3.2.3.3 核心API

**get()**

​	get操作的思路比较简单，和HashMap取值过程类似。

![image-20200801161754496](assets/image-20200801161754496.png)

**put()**

​	put操作较为复杂，需要考虑并发安全性的问题。

```java
/** Implementation for put and putIfAbsent */
final V putVal(K key, V value, boolean onlyIfAbsent) {
    if (key == null || value == null) throw new NullPointerException();
    int hash = spread(key.hashCode());
    int binCount = 0;
    for (Node<K,V>[] tab = table;;) {
        Node<K,V> f; int n, i, fh;
        if (tab == null || (n = tab.length) == 0)
            /*如果table为空，初始化table*/
            tab = initTable();
        else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
            /*CAS向Node数组中存值*/
            if (casTabAt(tab, i, null,
                         new Node<K,V>(hash, key, value, null)))
                break;                   // no lock when adding to empty bin
        }
        else if ((fh = f.hash) == MOVED)
            /*扩容操作，当前线程协助扩容*/
            tab = helpTransfer(tab, f);
        else {
            V oldVal = null;
            /*
			*基于synchronized锁住数组中的元素
			*/
            synchronized (f) {
                if (tabAt(tab, i) == f) {
                    /*是链表中的节点*/
                    if (fh >= 0) {
                        binCount = 1;
                        for (Node<K,V> e = f;; ++binCount) {
                            K ek;
                            /*存放数据*/
                            if (e.hash == hash &&
                                ((ek = e.key) == key ||
                                 (ek != null && key.equals(ek)))) {
                                oldVal = e.val;
                                if (!onlyIfAbsent)
                                    e.val = value;
                                break;
                            }
                            Node<K,V> pred = e;
                            /*如果遍历到了最后一个节点，则把它插入到链表尾部*/
                            if ((e = e.next) == null) {
                                pred.next = new Node<K,V>(hash, key,
                                                          value, null);
                                break;
                            }
                        }
                    }
                    /*按照树的方式插入值*/
                    else if (f instanceof TreeBin) {
                        Node<K,V> p;
                        binCount = 2;
                        if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,
                                                              value)) != null) {
                            oldVal = p.val;
                            if (!onlyIfAbsent)
                                p.val = value;
                        }
                    }
                }
            }
            if (binCount != 0) {
                /*达到阈值8，链表转换为红黑树*/
                if (binCount >= TREEIFY_THRESHOLD)
                    treeifyBin(tab, i);
                if (oldVal != null)
                    return oldVal;
                break;
            }
        }
    }
    /*Map元素数量+1，检查是否需要扩容*/
    addCount(1L, binCount);
    return null;
}
```



#### 3.2.3.4 与hashTable的区别

​	Hashtable的任何操作都会把整个表锁住，是阻塞的。好处是总能获取最实时的更新，比如说线程A调用putAll写入大量数据，期间线程B调用get，线程B就会被阻塞，直到线程A完成putAll，因此线程B肯定能获取到线程A写入的完整数据。坏处是所有调用都要排队，竞争越激烈效率越低。 更注重安全。

​	ConcurrentHashMap 是设计为非阻塞的。在更新时会局部锁住某部分数据，但不会把整个表都锁住。同步读取操作则是完全非阻塞的。好处是在保证合理的同步前提下，效率很高。坏处 是严格来说读取操作不能保证反映最近的更新。例如线程A调用putAll写入大量数据，期间线程B调用get，则只能get到目前为止已经顺利插入的部分数据。更注重性能。

# 4 队列

要实现一个线程安全的队列有两种方式：阻塞和非阻塞:

| queue                 | 阻塞与否 | 是否有界 | 线程安全保障  | 适用场景                       | 注意事项                      |
| --------------------- | -------- | -------- | ------------- | ------------------------------ | ----------------------------- |
| ConcurrentLinkedQueue | 非阻塞   | 无界     | CAS           | 对全局的集合进行操作的场景     | size() 是要遍历一遍集合，慎用 |
| ArrayBlockingQueue    | 阻塞     | 有界     | 一把全局锁    | 生产消费模型，平衡两边处理速度 | --                            |
| LinkedBlockingQueue   | 阻塞     | 可配置   | 存取采用2把锁 | 生产消费模型，平衡两边处理速度 | 无界的时候注意内存溢出问题    |
| PriorityBlockingQueue | 阻塞     | 无界     | 一把全局锁    | 支持优先级排序                 |                               |
| SynchronousQueue      | 阻塞     | 无界     | CAS           | 不存储元素的阻塞队列           |                               |

## 4.1 非阻塞队列ConcurrentLinkedQueue

​	在单线程编程中我们会经常用到一些集合类，比如ArrayList，HashMap等，但是这些类都不是线程安全的类。在面试中也经常会有一些考点，比如ArrayList不是线程安全的，Vector是线程安全。而保障Vector线程安全的方式，是非常粗暴的在方法上用synchronized独占锁，将多线程执行变成串行化。要想将ArrayList变成线程安全的也可以使用`Collections.synchronizedList(List<T> list)`方法ArrayList转换成线程安全的，但这种转换方式依然是通过synchronized修饰方法实现的，很显然这不是一种高效的方式，同时，队列也是我们常用的一种数据结构。

​	为了解决线程安全的问题，J.U.C为我们准备了ConcurrentLinkedQueue这个线程安全的队列。从类名就可以看的出来实现队列的数据结构是链式。ConcurrentLinkedQueue是一个基于链接节点的无边界的线程安全队列，遵循队列的FIFO原则，队尾入队，队首出队。采用CAS算法来实现的。

常用API:

1)

**offer(E e)，add(E e)：**将指定元素插入队列的尾部

**poll()：**获取并移除此队列的头，如果此队列为空，则返回null

```java
public class ConcurrentLinkedQueueDemo {

    public static void main(String[] args) {
        ConcurrentLinkedQueue queue = new ConcurrentLinkedQueue();
        queue.offer("java");
        System.out.println("offer后，队列是否空？" + queue.isEmpty());
        System.out.println("从队列中poll：" + queue.poll());
        System.out.println("pool后，队列是否空？" + queue.isEmpty());
    }
}
```

2）**peek()：**获取但不移除此队列的头，如果队列为空，则返回null；

```java
public class ConcurrentLinkedQueueDemo {

    public static void main(String[] args) {
        ConcurrentLinkedQueue queue = new ConcurrentLinkedQueue();
        queue.offer("java");
        System.out.println("从队列中peek：" + queue.peek());
        System.out.println("offer后，队列是否空？" + queue.isEmpty());
        System.out.println("从队列中poll：" + queue.poll());
        System.out.println("pool后，队列是否空？" + queue.isEmpty());
    }
}
```

3）**remove()：**从队列中删除指定元素。

```java
public class ConcurrentLinkedQueueDemo {

    public static void main(String[] args) {
        ConcurrentLinkedQueue queue = new ConcurrentLinkedQueue();
        queue.offer("java");
        queue.offer("python");
        System.out.println("offer后，队列是否空？" + queue.isEmpty());
        System.out.println("从队列中peek：" + queue.peek());
        System.out.println("从队列中poll：" + queue.poll());
        System.out.println("pool后，队列是否空？" + queue.isEmpty());
        System.out.println("从队列中remove元素:"+queue.remove("python"));
    }
}
```

注意：

1. ConcurrentLinkedQueue的.size() 是要遍历一遍集合的，很慢的，所以尽量不要用 queue.size()>0，而是用 !queue.isEmpty()

2. 使用了这个ConcurrentLinkedQueue 类之后还是需要自己进行同步或加锁操作。例如queue.isEmpty()后再进行队列操作queue.add()是不能保证安全的，因为可能queue.isEmpty()执行完成后，别的线程开始操作队列。


## 4.2 阻塞队列BlockingQueue 

### 4.2.1 BlockingQueue

​	BlockingQueue即阻塞队列，从阻塞这个词可以看出，在某些情况下对阻塞队列的访问可能会造成阻塞。被阻塞的情况主要有如下两种：

1. 当队列满了的时候进行入队列操作
2. 当队列空了的时候进行出队列操作

因此，当一个线程试图对一个已经满了的队列进行入队列操作时，它将会被阻塞，除非有另一个线程做了出队列操作；同样，当一个线程试图对一个空队列进行出队列操作时，它将会被阻塞，除非有另一个线程进行了入队列操作。

![87](assets\20150929153140497)



BlockingQueue 对插入操作、移除操作、获取元素操作提供了四类不同的策略用于不同的场景中使用：

1. 抛出异常
2. 返回特殊值（null 或 true/false，取决于具体的操作）
3. 阻塞等待此操作，直到这个操作成功
4. 阻塞等待此操作，直到成功或者超时指定时间。总结如下：

| 操作 | 抛出异常  | 特殊值   | 阻塞   | 超时                  |
| :--: | --------- | -------- | ------ | --------------------- |
| 插入 | add(e)    | offer(e) | put(e) | offer(e,  time, unit) |
| 移除 | remove()  | poll()   | take() | poll(time,  unit)     |
| 检查 | element() | peek()   | 不可用 | 不可用                |

接下来我们介绍这个接口的几个实现类。



### 4.2.2 ArrayBlockingQueue

​	ArrayBlockingQueue是一个由**数组**实现的**有界阻塞队列**。该队列采用**FIFO**的原则对元素进行排序添加的。

​	ArrayBlockingQueue为**有界**且**固定**，其大小在构造时由构造函数来决定，确认之后就不能再改变了。

​	ArrayBlockingQueue支持对等待的生产者线程和使用者线程进行排序的可选公平策略，但是在默认情况下不保证线程公平的访问，在构造时可以选择公平策略（fair = true）。公平性通常会降低吞吐量，但是减少了可变性和避免了“不平衡性”。

​	ArrayBlockingQueue内部使用可重入锁ReentrantLock + Condition来完成多线程环境的并发操作。

- items，一个定长数组，维护ArrayBlockingQueue的元素
- takeIndex，int，为ArrayBlockingQueue队首位置
- putIndex，int，ArrayBlockingQueue队尾位置
- count，元素个数
- lock，锁，ArrayBlockingQueue出列入列都必须获取该锁，两个步骤公用一个锁

```java
public class ArrayBlockingQueue<E> extends AbstractQueue<E> implements BlockingQueue<E>, Serializable {
    private static final long serialVersionUID = -817911632652898426L;
    final Object[] items;
    int takeIndex;
    int putIndex;
    int count;
    // 重入锁
    final ReentrantLock lock;
    // notEmpty condition
    private final Condition notEmpty;
    // notFull condition
    private final Condition notFull;
    transient ArrayBlockingQueue.Itrs itrs;
}
```

源码解析：

put过程

```java
 public void put(E e) throws InterruptedException {
        checkNotNull(e);//元素不能为空
        final ReentrantLock lock = this.lock;
        lock.lockInterruptibly();//加锁
        try {
            //如果元素个数等于数组长度，说明放满了
            while (count == items.length)
                notFull.await();//阻塞put线程
            enqueue(e);//存储当前元素到数组中
        } finally {
            lock.unlock();//解锁
        }
    }

private void enqueue(E x) {
        // assert lock.getHoldCount() == 1;
        // assert items[putIndex] == null;
        final Object[] items = this.items;
        items[putIndex] = x;//从下标为0位置开始存储元素
        if (++putIndex == items.length)
            putIndex = 0;//已经存到最后一个了，就重新开始计数
        count++;//增加数组元素个数
        notEmpty.signal();//唤醒take线程
    }
```

take过程：

````java
public E take() throws InterruptedException {
        final ReentrantLock lock = this.lock;
        lock.lockInterruptibly();//加锁
        try {
            while (count == 0)//队列为空
                notEmpty.await();//take线程等待
            return dequeue();//取出元素并返回
        } finally {
            lock.unlock();//解锁
        }
    }

 private E dequeue() {
        // assert lock.getHoldCount() == 1;
        // assert items[takeIndex] != null;
        final Object[] items = this.items;
        @SuppressWarnings("unchecked")
        E x = (E) items[takeIndex];//从下标为0的位置开始取元素
        items[takeIndex] = null;//取完之后将该位置设为null，移除该元素
        if (++takeIndex == items.length)
            takeIndex = 0;//已经取到最后一个了，就重新开始计数
        count--;//减少队列中元素个数
        if (itrs != null)//
            itrs.elementDequeued();
        notFull.signal();//唤醒put线程
        return x;
    }
````

使用示例：

```java
public class ArrayBlockingQueueDemo {
    
    //最大容量为5的数组阻塞队列
    private static ArrayBlockingQueue<Integer> queue = new ArrayBlockingQueue<Integer>(5, true);

    public static void main(String[] args) {

        Thread t1 = new Thread(new ProducerTask());
        Thread t2 = new Thread(new ConsumerTask());

        //启动线程  
        t1.start();
        t2.start();

    }

    //生产者
    static class ProducerTask implements Runnable {
        private Random rnd = new Random();

        @Override
        public void run() {
            try {
                while (true) {
                    int value = rnd.nextInt(100);
                    //如果queue容量已满，则当前线程会堵塞，直到有空间再继续
                    queue.put(value);

                    System.out.println("生产者：" + value);

                    TimeUnit.MILLISECONDS.sleep(100); //线程休眠
                }
            } catch (Exception e) {
            }
        }
    }

    //消费者
    static class ConsumerTask implements Runnable {
        @Override
        public void run() {
            try {
                while (true) {
                    //如果queue为空，则当前线程会堵塞，直到有新数据加入
                    Integer value = queue.take();

                    System.out.println("消费者:" + value);

                    TimeUnit.MILLISECONDS.sleep(15); //线程休眠
                }
            } catch (Exception e) {
            }
        }
    }
}
```

### 4.2.3 LinkedBlockingQueue

LinkedBlockingQueue和ArrayBlockingQueue的使用方式基本一样，但还是有一定的区别：

1. **队列的数据结构不同**

   ArrayBlockingQueue是一个由**数组**支持的有界阻塞队列

   LinkedBlockingQueue是一个基于**链表**的有界（可设置）阻塞队列

2. **队列大小初始化方式不同**

   ArrayBlockingQueue实现的队列中必须指定队列的大小；

   LinkedBlockingQueue实现的队列中可以不指定队列的大小，但是默认是Integer.MAX_VALUE

3. **队列中锁的实现不同**

​        ArrayBlockingQueue实现的队列中的锁是没有分离的，即生产和消费用的是同一个锁；

​        LinkedBlockingQueue实现的队列中的锁是分离的，即生产用的是putLock，消费是takeLock

​	4. **在生产或消费时操作不同**

​        ArrayBlockingQueue实现的队列中在生产和消费的时候，是直接将枚举对象插入或移除的；

​        LinkedBlockingQueue实现的队列中在生产和消费的时候，需要把枚举对象转换为Node<E>进行插入或移除，会影响性能

**源码解析：**

put过程

````java
public void put(E e) throws InterruptedException {
        if (e == null) throw new NullPointerException();
        // Note: convention in all put/take/etc is to preset local var
        // holding count negative to indicate failure unless set.
        int c = -1;
        Node<E> node = new Node<E>(e);//将当前元素作为节点保存
        final ReentrantLock putLock = this.putLock;//put锁
        final AtomicInteger count = this.count;//count值
        putLock.lockInterruptibly();//加锁
        try {
            /*
             * Note that count is used in wait guard even though it is
             * not protected by lock. This works because count can
             * only decrease at this point (all other puts are shut
             * out by lock), and we (or some other waiting put) are
             * signalled if it ever changes from capacity. Similarly
             * for all other uses of count in other wait guards.
             */
            while (count.get() == capacity) {//放满了
                notFull.await();//让put线程等待
            }
            enqueue(node);//入队
            c = count.getAndIncrement();//1.修改count+1,并返回修改之前的值
            if (c + 1 < capacity)//还能再放一个元素入队
                notFull.signal();//唤醒一个put线程
        } finally {
            putLock.unlock();//解锁
        }
        if (c == 0)//修改之前队列是空的
            signalNotEmpty();//唤醒take线程
    }

//1.将当前节点作为原尾节点的next
//2.设置新的尾节点为当前节点
 private void enqueue(Node<E> node) {
        // assert putLock.isHeldByCurrentThread();
        // assert last.next == null;
        last = last.next = node;
    }
````

take过程：

````java
public E take() throws InterruptedException {
        E x;
        int c = -1;
        final AtomicInteger count = this.count;
        final ReentrantLock takeLock = this.takeLock;
        takeLock.lockInterruptibly();//加锁
        try {
            while (count.get() == 0) {//队列为空
                notEmpty.await();//取得线程等待
            }
            x = dequeue();//队列不为空，取出元素
            c = count.getAndDecrement();//减少count值，并返回修改之前的值
            if (c > 1)//如果还能取一个元素出来
                notEmpty.signal();//唤醒一个take线程
        } finally {
            takeLock.unlock();//解锁
        }
        if (c == capacity)//在本次操作之前，队列是满的
            signalNotFull();//唤醒put线程
        return x;
    }

private E dequeue() {
        // assert takeLock.isHeldByCurrentThread();
        // assert head.item == null;
    	//获取当前的头结点
        Node<E> h = head;
    	//头结点的下一个节点
        Node<E> first = h.next;
    	//设置头结点的下一个节点为头结点，断开连接
        h.next = h; // help GC
    	//设置新的头结点
        head = first;
    	//获取first中的元素
        E x = first.item;
    	//获取完了就指向null，帮助gc
        first.item = null;
    	//返回元素
        return x;
    }
````

### 4.2.4 PriorityBlockingQueue

​	PriorityBlockingQueue类似于ArrayBlockingQueue内部使用一个独占锁来控制，同时只有一个线程可以进行入队和出队。

​	PriorityBlockingQueue是一个**优先级队列**，它在java.util.PriorityQueue的基础上提供了**可阻塞**的读取操作。它是**无界**的，就是说向Queue里面增加元素没有数量限制，但可能会导致内存溢出而失败。

　PriorityBlockingQueue始终保证出队的元素是**优先级最高**的元素，并且可以定制优先级的规则，内部通过数组保存元素，这个数组是可扩容的，当**当前元素个数>=最大容量时候会通过算法扩容**。值得注意的是为了避免在扩容操作时候其他线程不能进行出队操作，实现上使用了先释放锁，然后通过CAS保证同时只有一个线程可以扩容成功。

注意：

1、优先队列不允许空值，而且不支持non-comparable（不可比较）的对象，比如用户自定义的类。优先队列要求使用Java Comparable和Comparator接口给对象排序，并且在排序时会按照优先级处理其中的元素。

2、优先队列的头是基于自然排序或者Comparator排序的最小元素。如果有多个对象拥有同样的排序，那么就可能随机地取其中任意一个。也可以通过提供的Comparator（比较器）在队列实现自定的排序。当我们获取队列时，返回队列的头对象。

3、优先队列的大小是不受限制的，但在创建时可以指定初始大小，当我们向优先队列增加元素的时候，队列大小会自动增加。

4、PriorityQueue是非线程安全的，所以Java提供了PriorityBlockingQueue（实现BlockingQueue接口）用于Java多线程环境。

源码解析

put过程：

````java
public void put(E e) {
        offer(e); // never need to block
    }

 public boolean offer(E e) {
        if (e == null)
            throw new NullPointerException();
        final ReentrantLock lock = this.lock;
        lock.lock();//加锁
        int n, cap;
        Object[] array;
     	//如果元素个数大于等于数组长度，开始扩容
        while ((n = size) >= (cap = (array = queue).length))
            tryGrow(array, cap);
        try {
            //一开始构建队列的时候传入comparator
            Comparator<? super E> cmp = comparator;
            if (cmp == null)
                //使用元素自带的comparator进行比较，并排序
                siftUpComparable(n, e, array);
            else
                //使用comparator进行比较，并排序
                siftUpUsingComparator(n, e, array, cmp);
            size = n + 1;//增加元素个数
            notEmpty.signal();//唤醒take线程
        } finally {
            lock.unlock();//解锁
        }
        return true;
    }

 private void tryGrow(Object[] array, int oldCap) {
     	//扩容期间需要解锁，能够让其他线程继续执行
        lock.unlock(); // must release and then re-acquire main lock
        Object[] newArray = null;//新数组
     	//cas标识，如果为0，表示当前没有线程对数组扩容
        if (allocationSpinLock == 0 &&
            //cas方式设置值0->1
            UNSAFE.compareAndSwapInt(this, allocationSpinLockOffset,
                                     0, 1)) {
            try {
                //开始扩容
                //计算新的数组长度
                int newCap = oldCap + ((oldCap < 64) ?
                                       (oldCap + 2) : // grow faster if small
                                       (oldCap >> 1));
                //计算容量不能超过最大大小
                if (newCap - MAX_ARRAY_SIZE > 0) {    // possible overflow
                    int minCap = oldCap + 1;
                    if (minCap < 0 || minCap > MAX_ARRAY_SIZE)
                        throw new OutOfMemoryError();
                    newCap = MAX_ARRAY_SIZE;
                }
                if (newCap > oldCap && queue == array)
                    newArray = new Object[newCap];//创建新的数组用来保存元素
            } finally {
                allocationSpinLock = 0;//重置标识，表示扩容完毕
            }
        }
        if (newArray == null) // back off if another thread is allocating
            Thread.yield();
        lock.lock();//重新加锁
     	//如果数组还是原来的数组
        if (newArray != null && queue == array) {
            queue = newArray;//设置为新数组
            System.arraycopy(array, 0, newArray, 0, oldCap);//转移元素到新数组
        }
    }
````

take

````java
 public E take() throws InterruptedException {
        final ReentrantLock lock = this.lock;
        lock.lockInterruptibly();//加锁
        E result;
        try {
            while ( (result = dequeue()) == null)
                notEmpty.await();
        } finally {
            lock.unlock();
        }
        return result;
    }

private E dequeue() {
        int n = size - 1;
        if (n < 0)
            return null;//队列为空
        else {
            Object[] array = queue;
            E result = (E) array[0];//取出第一个
            E x = (E) array[n];
            array[n] = null;//设置为空
            Comparator<? super E> cmp = comparator;
            if (cmp == null)
                siftDownComparable(0, x, array, n);
            else
                siftDownUsingComparator(0, x, array, n, cmp);
            size = n;
            return result;
        }
    }
````



### 4.2.5 SynchronousQueue

​	SynchronousQueue，实际上它不是一个真正的队列，因为它不会为队列中元素维护存储空间。与其他队列不同的是，它维护一组线程，这些线程在等待着把元素加入或移出队列。SynchronousQueue没有存储功能，因此put和take会一直阻塞，直到有另一个线程已经准备好参与到交付过程中。

​	仅当有足够多的消费者，并且总是有一个消费者准备好获取交付的工作时，才适合使用同步队列。这种实现队列的方式看似很奇怪，但由于可以直接交付工作，从而降低了将数据从生产者移动到消费者的延迟。

​	直接交付方式还会将更多关于任务状态的信息反馈给生产者。当交付被接受时，它就知道消费者已经得到了任务，而不是简单地把任务放入一个队列——这种区别就好比将文件直接交给同事，还是将文件放到她的邮箱中并希望她能尽快拿到文件。


​	SynchronousQueue对于正在等待的生产者和使用者线程而言，默认是非公平排序，也可以选择公平排序策略。但是，使用公平所构造的队列可保证线程以 FIFO 的顺序进行访问。 公平通常会降低吞吐量，但是可以减小可变性并避免得不到服务。 



SynchronousQueue特点：

* 是一种**阻塞队列**，其中每个 put 必须等待一个 take，反之亦然。同步队列没有任何内部容量，甚至连一个队列的容量都没有。 
* 是线程安全的，是阻塞的。 
* 不允许使用 null 元素。 
* 公平排序策略是指调用put的线程之间，或take的线程之间的线程以 FIFO 的顺序进行访问。
* SynchronousQueue的方法： 

  * iterator()： 永远返回空，因为里面没东西。 
  * peek() ：永远返回null。 
  * put() ：往queue放进去一个element以后就一直wait直到有其他thread进来把这个element取走。 
  * offer() ：往queue里放一个element后立即返回，如果碰巧这个element被另一个thread取走了，offer方法返回true，认为offer成功；否则返回false。 
  * offer(2000, TimeUnit.SECONDS) ：往queue里放一个element但等待时间后才返回，和offer()方法一样。 
  * take() ：取出并且remove掉queue里的element，取不到东西他会一直等。 
  * poll() ：取出并且remove掉queue里的element，方法立即能取到东西返回。否则立即返回null。 
  * poll(2000, TimeUnit.SECONDS) ：等待时间后再取，并且remove掉queue里的element,
  * isEmpty()：永远是true。 
  * remainingCapacity() ：永远是0。 
  * remove()和removeAll() ：永远是false。 

# 5 ThreadPoolExecutor线程池

## 5.1 为什么使用线程池

​	对于线程的创建和切换代价都是比较大的，为了能够更好的使用线程，所以就产生了线程池的概念。Java中的线程池是运用场景最多的并发框架，几乎所有需要异步或并发执行任务的程序都可以使用线程池。其带来的好处如下：

- 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。

- 提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。

- 提高线程的可管理性。线程是稀缺资源，要合理利用分配，通过线程池可以进行统一分配、调优和监控。

## 5.2 线程池状态

![image-20200801165159637](assets/image-20200801165159637.png)

线程池存在五种状态：RUNNING、 SHUTDOWN,、STOP、TIDYING、TERMINATED。

* **RUNNING**：处于RUNNING状态的线程池能够接受新任务，以及对新添加的任务进行处理。
* **SHUTDOWN**：处于SHUTDOWN状态的线程池不可以接受新任务，但是可以对已添加的任务进行处理。
* **STOP**：处于STOP状态的线程池不接收新任务，不处理已添加的任务，并且会中断正在处理的任务。
* **TIDYING**：当所有的任务已终止，线程池会变为TIDYING状态。当线程池变为TIDYING状态时，会执行钩子函数terminated()。terminated()在ThreadPoolExecutor类中是空的，若用户想在线程池变为TIDYING时，进行相应的处理；可以通过重载terminated()函数来实现。
* **TERMINATED**：线程池彻底终止的状态。

![image-20200801165350954](assets/image-20200801165350954.png)

## 5.3 线程池创建的各个参数含义

![image-20200801165625614](assets/image-20200801165625614.png)

**corePoolSize：**

​	核心线程数(线程池基本大小)，在没有任务需要执行的时候的线程池大小。当提交一个任务时，线程池创建一个新线程执行任务，直到线程数等于该参数。 如果当前线程数为该参数，后续提交的任务被保存到阻塞队列中，等待被执行。

**maximumPoolSize：**

​	线程池中允许的最大线程数，线程池中的当前线程数目不会超过该值。如果当前阻塞队列满了，且继续提交任务，如果当前的线程数小于maximumPoolSize，则会新建线程来执行任务。

**keepAliveTime：**

​	线程池空闲时的存活时间，即当线程池没有任务执行时，继续存活的时间。默认情况下，该参数只在线程数大于corePoolSize时才有用。

**workQueue：**

​	其必须是BolckingQueue有界阻塞队列，用于实现线程池的阻塞功能。当线程池中的线程数超过它的corePoolSize时，线程会进入阻塞队列进行阻塞等待。

**threadFactory**：

​	用于设置创建线程的工厂。ThreadFactory的作用就是提供创建线程的功能的线程工厂。他是通过newThread()方法提供创建线程的功能，newThread()方法创建的线程都是“非守护线程”而且“线程优先级都是默认优先级”。

**handler：**

​	线程池拒绝策略。当阻塞队列满了，且没有空闲的工作线程，如果继续提交任务，则必须采取一种策略处理该任务。

AbortPolicy：默认策略，直接抛出异常。

CallerRunsPolicy：用调用者所在的线程执行任务。

DiscardOldestPolicy：丢去阻塞队列的头部任务，并执行当前任务。

DiscardPolicy：直接丢弃任务。

## 5.4 线程池工作机制

1. 如果当前运行的线程少于corePoolSize，则创建新线程来执行任务（执行这一步前，需要获取全局锁）。
2. 如果运行的线程等于或多于corePoolSize，则将任务加入BlockingQueue。
3. 如果无法将任务加入BlockingQueue，则创建新线程处理任务。
4. 如果创建的新线程使当前运行的线程超出maximumPoolSize，任务将被拒绝。

## 5.5 自定义线程池

```java
public class ThreadPoolDemo {

    public static void main(String[] args) {

        //创建阻塞队列
        LinkedBlockingQueue<Runnable> queue = new LinkedBlockingQueue<>(100);

        //创建工厂
        ThreadFactory threadFactory = new ThreadFactory() {

            AtomicInteger atomicInteger = new AtomicInteger(1);
            @Override
            public Thread newThread(Runnable r) {

                //创建线程把任务传递进去
                Thread thread = new Thread(r);
                //设置线程名称
                thread.setName("MyThread: "+atomicInteger.getAndIncrement());
                return thread;
            }
        };

        ThreadPoolExecutor pool  = new ThreadPoolExecutor(10,
                                                          10,
                                                          1,
                                                          TimeUnit.SECONDS,
                                                          queue,
                                                          threadFactory);

        for (int i = 0; i < 100; i++) {

            pool.execute(new Runnable() {
                @Override
                public void run() {
                    //执行业务
                    System.out.println(Thread.currentThread().getName()+" 进来了");
                    try {
                        Thread.sleep(2000);
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                    System.out.println(Thread.currentThread().getName()+"出去了");
                }
            });
        }
    }
}
```

## 5.5 五种预定义线程池

​	我们除了可以使用ThreadPoolExecutor自己根据实际情况创建线程池以外，Executor框架也提供了四种线程池，他们都可以通过工具类Executors来创建。

​	还有一种线程池ScheduledThreadPoolExecutor，它相当于提供了“延迟”和“周期执行”功能的ThreadPoolExecutor。

### 5.5.1 FixedThreadPool

​	创建使用固定线程数的线程池。适用于为了满足资源管理而需要限制当前线程数量的场景。同时也适用于负载较重的服务器。其定义如下：

```java
public static ExecutorService newFixedThreadPool(int nThreads) {
    return new ThreadPoolExecutor(nThreads, nThreads,
                                  0L, TimeUnit.MILLISECONDS,
                                      new LinkedBlockingQueue<Runnable>());
}
```

**nThreads**：

​	FixedThreadPool 的 corePoolSize 和 maximumPoolSize 都被设置为创建FixedThreadPool 时指定的参数 nThreads。

**keepAliveTime**：

​	此处设置为了0L，代表多于的空闲线程会被立即终止。

**LinkedBlockingQueue**：

FixedThreadPool 使用有界队列 LinkedBlockingQueue 作为线程池的工作队列（队列的容量为 Integer.MAX_VALUE）。

![img](assets\2018120835002.png)

```java
public class FixedThreadPoolCase {

    static class Demo implements Runnable {
        @Override
        public void run() {
            String name = Thread.currentThread().getName();
            for (int i = 0; i < 2; i++) {
                System.out.println(name + ":" + i);
            }
        }
    }

    public static void main(String[] args) throws InterruptedException {

        ExecutorService exec = Executors.newFixedThreadPool(3);

        for (int i = 0; i < 5; i++) {
            exec.execute(new Demo());
            Thread.sleep(10);
        }
        exec.shutdown();
    }


}
```

### 5.5.2 SingleThreadExecutor

​	只会使用单个工作线程来执行一个无边界的队列。适用于保证顺序地执行各个人物，并且在任意时间点，不会有多个线程存在活动的应用场景。

```java
public static ExecutorService newSingleThreadExecutor() {
    return new FinalizableDelegatedExecutorService
        (new ThreadPoolExecutor(1, 1,
                                0L, TimeUnit.MILLISECONDS,
                                new LinkedBlockingQueue<Runnable>()));
}
```

​	corePoolSize 和 maximumPoolSize 被设置为 1。其他参数与 FixedThreadPool相同。SingleThreadExecutor 使用有界队列 LinkedBlockingQueue 作为线程池的工作队列（队列的容量为 Integer.MAX_VALUE）。

![img](assets\2018120835006.png)

```java
public class SingleThreadPoolCase {
    
    static int count = 0;

    public static void main(String[] args) throws InterruptedException {
        
        ExecutorService exec = Executors.newSingleThreadExecutor();
        
        for (int i = 0; i < 10; i++) {
            exec.execute(new Demo());
            Thread.sleep(5);
        }
        exec.shutdown();
    }

    static class Demo implements Runnable {
        @Override
        public void run() {
            String name = Thread.currentThread().getName();
            for (int i = 0; i < 2; i++) {
                count++;
                System.out.println(name + ":" + count);
            }
        }
    }
}
```

### 5.5.3 CachedThreadPool

​	其是一个大小无界的线程池，会根据需要创建新线程。适用于执行很多的短期异步任务的小程序或者是负载较轻的服务器。

```java
public static ExecutorService newCachedThreadPool() {
    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                  60L, TimeUnit.SECONDS,
                                  new SynchronousQueue<Runnable>());
}
```

​	corePoolSize 被设置为 0，即 corePool 为空；maximumPoolSize 被设置为Integer.MAX_VALUE。这里把 keepAliveTime 设置为 60L，意味着 CachedThreadPool中的空闲线程等待新任务的最长时间为60秒，空闲线程超过60秒后将会被终止。

​	FixedThreadPool 和 SingleThreadExecutor 使用有界队列 LinkedBlockingQueue作为线程池的工作队列。CachedThreadPool 使用没有容量的 SynchronousQueue作为线程池的工作队列，但 CachedThreadPool 的 maximumPool 是无界的。这意味着，如果主线程提交任务的速度高于 maximumPool 中线程处理任务的速度时，
CachedThreadPool 会不断创建新线程。极端情况下，CachedThreadPool 会因为创建过多线程而耗尽 CPU 和内存资源。

![image-20200801182645368](assets/image-20200801182645368.png)

```java
public class Demo9CachedThreadPoolCase {
    public static void main(String[] args) throws InterruptedException {
        ExecutorService exec = Executors.newCachedThreadPool();
        for (int i = 0; i < 10; i++) {
            exec.execute(new Demo());
            Thread.sleep(1);
        }
        exec.shutdown();
    }

    static class Demo implements Runnable {
        @Override
        public void run() {
            String name = Thread.currentThread().getName();
            try {
                //修改睡眠时间，模拟线程执行需要花费的时间
                Thread.sleep(1);

                System.out.println(name + "执行完了");
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
    }
}
```

### 5.5.4 ScheduledThreadPoolExecutor

​	ScheduledThreadPoolExecutor，继承ThreadPoolExecutor且实现了ScheduledExecutorService接口，它就相当于提供了“延迟”和“周期执行”功能的ThreadPoolExecutor。它可另行安排在给定的延迟后运行命令，或者定期执行命令。它适用于为了满足资源管理的需求而需要限制后台线程数量的场景同时可以保证多任务的顺序执行。

```java
    public ScheduledThreadPoolExecutor(int corePoolSize) {
        super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,
                new DelayedWorkQueue());
    }

    public ScheduledThreadPoolExecutor(int corePoolSize,
                                       ThreadFactory threadFactory) {
        super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,
                new DelayedWorkQueue(), threadFactory);
    }

    public ScheduledThreadPoolExecutor(int corePoolSize,
                                       RejectedExecutionHandler handler) {
        super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,
                new DelayedWorkQueue(), handler);
    }


    public ScheduledThreadPoolExecutor(int corePoolSize,
                                       ThreadFactory threadFactory,
                                       RejectedExecutionHandler handler) {
        super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,
                new DelayedWorkQueue(), threadFactory, handler);
    }
```

​	在ScheduledThreadPoolExecutor的构造函数中，我们发现它都是利用ThreadLocalExecutor来构造的，唯一变动的地方就在于它所使用的阻塞队列变成了DelayedWorkQueue。

​	DelayedWorkQueue为ScheduledThreadPoolExecutor中的内部类，类似于延时队列和优先级队列。在执行定时任务的时候，每个任务的执行时间都不同，所以DelayedWorkQueue的工作就是按照执行时间的升序来排列，执行时间距离当前时间越近的任务在队列的前面，这样就可以保证每次出队的任务都是当前队列中执行时间最靠前的。

```java
public class Demo9ScheduledThreadPool {

    public static void main(String[] args) throws InterruptedException {
        ScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(2);
        System.out.println("程序开始：" + new Date());
        // 第二个参数是延迟多久执行
        scheduledThreadPool.schedule(new Task(), 0, TimeUnit.SECONDS);
        scheduledThreadPool.schedule(new Task(), 1, TimeUnit.SECONDS);
        scheduledThreadPool.schedule(new Task(), 5, TimeUnit.SECONDS);

        Thread.sleep(5000);

        // 关闭线程池
        scheduledThreadPool.shutdown();
    }

    static class Task implements Runnable {
        @Override
        public void run() {
            try {
                String name = Thread.currentThread().getName();

                System.out.println(name + ", 开始：" + new Date());
                Thread.sleep(1000);
                System.out.println(name + ", 结束：" + new Date());

            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
    }
}
```



### 5.5.5 WorkStealingPool

​	其是JDK1.8中新增的线程池，利用所有运行的CPU来创建一个工作窃取的线程池，是对ForkJoinPool的扩展，适用于非常耗时的操作。

```java
public class WorkStealingPoolDemo {

    public static void main(String[] args) throws IOException {

        //获取当前可用CPU核数
        System.out.println(Runtime.getRuntime().availableProcessors());

        //创建线程池
        ExecutorService stealingPool = Executors.newWorkStealingPool();
        stealingPool.execute(new MyThread(1000));

        /**
         * 我现在CPU是8个，开启了9个线程，第一个线程一秒执行完，其他的都是两秒
         * 此时会有一个线程进行等待，当第一个执行完毕后，会偷取第九个线程执行
         */
        for (int i = 0; i < Runtime.getRuntime().availableProcessors(); i++) {
            stealingPool.execute(new MyThread(2000));
        }

        // 因为work stealing 是deamon线程
        // 所以当main方法结束时, 此方法虽然还在后台运行,但是无输出
        // 可以通过对主线程阻塞解决
        System.in.read();

    }

    static class MyThread implements Runnable{

        int time;

        public MyThread(int time) {
            this.time = time;
        }

        @Override
        public void run() {
            try {
                TimeUnit.MILLISECONDS.sleep(time);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            System.out.println(Thread.currentThread().getName()+" : "+time);
        }
    }
}
```

![image-20200801184347585](assets/image-20200801184347585.png)

